import time
import praw
import re
import urllib2
import signal, sys
import itemparser as ip
import OAuth2Util
import redis
import json

footer_text = u"---\n\n^^Questions? ^^Message ^^/u/ha107642 ^^\u2014 ^^Call ^^wiki ^^pages ^^\\(e.g. ^^items ^^or ^^gems)) ^^with ^^[[NAME]] ^^\u2014 ^^I ^^will ^^only ^^post ^^panels ^^for ^^*unique* ^^items ^^\u2014 ^^[Github](https://github.com/ha107642/RedditPoEBot/)\n"

# Are comments, submissions and messages really unique among each other?
# Can a comment and a private message have the same ID?
def is_parsed(id):
    return redis.sismember("parsed_comments", id)

def add_parsed(id):
    return redis.sadd("parsed_comments", id)

def bot_comments():
    sub_comments = subreddit.get_comments()
    for comment in sub_comments:
        # Checks if the post is not actually the bot itself (since the details say [[NAME]])
        if not is_parsed(comment.id) and not str(comment.author) == username:
            reply = build_reply(comment.body)
            if reply:
                try:
                    comment.reply(reply)
                except Exception, e:
                    print str(e)
            # Add the post to the set of parsed comments
            add_parsed(comment.id)

def bot_submissions():
    sub_subs = subreddit.get_new(limit=5)
    for submission in sub_subs:
        if not is_parsed(submission.id):
            reply = build_reply(submission.selftext)
            if reply:
                try:
                    submission.add_comment(reply)
                except Exception, e:
                    print str(e)
            add_parsed(submission.id)

def bot_messages():
    msg_messages = r.get_messages(limit=20)
    for message in msg_messages:
        if not is_parsed(message.id):
            reply = build_reply(message.body)
            if reply:
                try:
                    message.reply(reply)
                except Exception, e:
                    print str(e)
            add_parsed(message.id)

# Regex Magic that finds the text encaptured with [[ ]]
pattern = re.compile("\[\[([^\[\]]*)\]\]")

def build_reply(text):
    reply = ""
    if text is None: return reply 
    links = pattern.findall(text)
    if len(links) == 0: return reply
    # Remove duplicates
    unique_links = []
    for i in links:
        if i not in unique_links:
            unique_links.append(i)
    # Because a comment can only have a max length, limit to only the first 30 requests
    if len(unique_links) > 30: unique_links = unique_links[0:30]
    for i in unique_links:
        print i
        name, link = lookup_name(i)
        if link is None: continue
        page = get_page(link)
        if page is None: continue
        reply += "[%s](%s)\n\n" % (name, link.replace("(", "\\(").replace(")", "\\)"))
        reply += ip.parse_item(page)
    if reply is "": 
        return None        
    return reply + footer_text

# Fetches a page and returns the response.
def get_page(link):
    try:
        request = urllib2.Request(link, headers={"User-Agent": "PoEWiki"})
        response = urllib2.urlopen(request)
        return response.read()
    except urllib2.HTTPError, e:
        return None
    except AttributeError, e:
        print "ERROR: %s" % str(e)
        return None

def lookup_name(name):
    name = urllib2.quote(name)
    search_url = "http://pathofexile.gamepedia.com/api.php?action=opensearch&search=%s" % name
    response = get_page(search_url)
    hits = json.loads(response)
    # opensearch returns a json array in a SoA fashion, 
    # where arr[0] is the search text, arr[1] matching pages,
    # arr[2] ??, arr[3] links to the matching pages.
    # e.g. ["facebreaker",["Facebreaker","FacebreakerUnarmedMoreDamage"],["",""],["http://pathofexile.gamepedia.com/Facebreaker","http://pathofexile.gamepedia.com/FacebreakerUnarmedMoreDamage"]]
    if len(hits[1]) == 0:
        return (None, None) # If we did not find anything, return None. 
    return (hits[1][0], hits[3][0]) # Otherwise, return the first match in a tuple with (name, url).

def signal_handler(signal, frame):
    redis.save()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)

# This string is sent by praw to reddit in accordance to the API rules
user_agent = ("REDDIT Bot v1.4 by /u/ha107642")
r = praw.Reddit(user_agent=user_agent)

redis = redis.StrictRedis(host="localhost")

oauth = OAuth2Util.OAuth2Util(r)
username = r.get_me().name

# Fill in the subreddit(s) here. Multisubs are done with + (e.g. MagicTCG+EDH)
subreddit = r.get_subreddit('pathofexile')

# Infinite loop that calls the function. The function outputs the post-ID's of all parsed comments.
# The ID's of parsed comments is compared with the already parsed comments so the list stays clean
# and memory is not increased. It sleeps for 15 seconds to wait for new posts.
while True:
    bot_comments()
    time.sleep(5)
    bot_submissions()
    time.sleep(5)
    bot_messages()
    oauth.refresh()
    time.sleep(5)
